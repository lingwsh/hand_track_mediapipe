{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824317af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv2.flip(cv2.imread(file), 1)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print handedness and draw hand landmarks on the image.\n",
    "    print('Handedness:', results.multi_handedness)\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    image_height, image_width, _ = image.shape\n",
    "    annotated_image = image.copy()\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "      print('hand_landmarks:', hand_landmarks)\n",
    "      print(\n",
    "          f'Index finger tip coordinates: (',\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "      )\n",
    "      mp_drawing.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks,\n",
    "          mp_hands.HAND_CONNECTIONS,\n",
    "          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "          mp_drawing_styles.get_default_hand_connections_style())\n",
    "    cv2.imwrite(\n",
    "        '/tmp/annotated_image' + str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e70f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handedness: [classification {\n",
      "  index: 1\n",
      "  score: 0.9989265203475952\n",
      "  label: \"Right\"\n",
      "}\n",
      ", classification {\n",
      "  index: 0\n",
      "  score: 0.9999997615814209\n",
      "  label: \"Left\"\n",
      "}\n",
      "]\n",
      "hand_landmarks: landmark {\n",
      "  x: 0.8887220025062561\n",
      "  y: 0.6618896126747131\n",
      "  z: -6.163275975268334e-05\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8346271514892578\n",
      "  y: 0.6900933384895325\n",
      "  z: -0.02781970612704754\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7790340781211853\n",
      "  y: 0.6664979457855225\n",
      "  z: -0.04415484890341759\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7341691255569458\n",
      "  y: 0.6388661861419678\n",
      "  z: -0.06289689242839813\n",
      "}\n",
      "landmark {\n",
      "  x: 0.6943821310997009\n",
      "  y: 0.6247417330741882\n",
      "  z: -0.08631810545921326\n",
      "}\n",
      "landmark {\n",
      "  x: 0.793049156665802\n",
      "  y: 0.5479297637939453\n",
      "  z: -0.013316958211362362\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7569113373756409\n",
      "  y: 0.4799182116985321\n",
      "  z: -0.028702132403850555\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7340813279151917\n",
      "  y: 0.4370258152484894\n",
      "  z: -0.04570832476019859\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7148194313049316\n",
      "  y: 0.40120184421539307\n",
      "  z: -0.05747854337096214\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8247486352920532\n",
      "  y: 0.5213472843170166\n",
      "  z: -0.017641251906752586\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7930312752723694\n",
      "  y: 0.4450652003288269\n",
      "  z: -0.029074208810925484\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7740585803985596\n",
      "  y: 0.395998477935791\n",
      "  z: -0.05248577147722244\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7583291530609131\n",
      "  y: 0.3529474139213562\n",
      "  z: -0.07034613192081451\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8612823486328125\n",
      "  y: 0.5118547081947327\n",
      "  z: -0.02473989501595497\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8339347839355469\n",
      "  y: 0.43573451042175293\n",
      "  z: -0.04046931117773056\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8171309232711792\n",
      "  y: 0.38933807611465454\n",
      "  z: -0.06086263060569763\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8007908463478088\n",
      "  y: 0.34879976511001587\n",
      "  z: -0.07531743496656418\n",
      "}\n",
      "landmark {\n",
      "  x: 0.9020599126815796\n",
      "  y: 0.515216588973999\n",
      "  z: -0.03478880971670151\n",
      "}\n",
      "landmark {\n",
      "  x: 0.893290638923645\n",
      "  y: 0.4510638415813446\n",
      "  z: -0.055767275393009186\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8854162693023682\n",
      "  y: 0.41251641511917114\n",
      "  z: -0.06971026957035065\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8752450942993164\n",
      "  y: 0.3766612708568573\n",
      "  z: -0.0792037695646286\n",
      "}\n",
      "\n",
      "Index finger tip coordinates: ( 1029.3399810791016, 433.2979917526245)\n",
      "hand_landmarks: landmark {\n",
      "  x: 0.22548231482505798\n",
      "  y: 0.7097495794296265\n",
      "  z: -5.929651524638757e-05\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2875458598136902\n",
      "  y: 0.7221216559410095\n",
      "  z: -0.018223583698272705\n",
      "}\n",
      "landmark {\n",
      "  x: 0.34259793162345886\n",
      "  y: 0.6795403957366943\n",
      "  z: -0.016118431463837624\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3786556124687195\n",
      "  y: 0.6299324035644531\n",
      "  z: -0.012572940438985825\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4124363660812378\n",
      "  y: 0.6056628227233887\n",
      "  z: -0.012481283396482468\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3205012083053589\n",
      "  y: 0.5705718994140625\n",
      "  z: -0.003587899496778846\n",
      "}\n",
      "landmark {\n",
      "  x: 0.35136541724205017\n",
      "  y: 0.5044391751289368\n",
      "  z: 0.001537524163722992\n",
      "}\n",
      "landmark {\n",
      "  x: 0.36951062083244324\n",
      "  y: 0.468231737613678\n",
      "  z: -0.00019504614465404302\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3842204213142395\n",
      "  y: 0.43488258123397827\n",
      "  z: -0.00265223509632051\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2874084711074829\n",
      "  y: 0.5482962727546692\n",
      "  z: -0.0033693937584757805\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3124227821826935\n",
      "  y: 0.46894827485084534\n",
      "  z: -0.0022937748581171036\n",
      "}\n",
      "landmark {\n",
      "  x: 0.33012208342552185\n",
      "  y: 0.41976702213287354\n",
      "  z: -0.015224688686430454\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3421667218208313\n",
      "  y: 0.37419116497039795\n",
      "  z: -0.0300246924161911\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2533945143222809\n",
      "  y: 0.5438945293426514\n",
      "  z: -0.004565701354295015\n",
      "}\n",
      "landmark {\n",
      "  x: 0.27038949728012085\n",
      "  y: 0.4613952040672302\n",
      "  z: -0.011273673735558987\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2839547097682953\n",
      "  y: 0.4148908853530884\n",
      "  z: -0.024680987000465393\n",
      "}\n",
      "landmark {\n",
      "  x: 0.29554861783981323\n",
      "  y: 0.3713887333869934\n",
      "  z: -0.038378458470106125\n",
      "}\n",
      "landmark {\n",
      "  x: 0.21826587617397308\n",
      "  y: 0.5524617433547974\n",
      "  z: -0.006980412639677525\n",
      "}\n",
      "landmark {\n",
      "  x: 0.22266525030136108\n",
      "  y: 0.4882086217403412\n",
      "  z: -0.021951766684651375\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2264290302991867\n",
      "  y: 0.44885367155075073\n",
      "  z: -0.03530392423272133\n",
      "}\n",
      "landmark {\n",
      "  x: 0.22975420951843262\n",
      "  y: 0.4100496768951416\n",
      "  z: -0.04679008945822716\n",
      "}\n",
      "\n",
      "Index finger tip coordinates: ( 553.2774066925049, 469.67318773269653)\n"
     ]
    }
   ],
   "source": [
    "# test on read one image\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For static images:\n",
    "img = \"data/01_hand_small.jpeg\"\n",
    "IMAGE_FILES = []\n",
    "IMAGE_FILES.append(img)\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv2.flip(cv2.imread(file), 1)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print handedness and draw hand landmarks on the image.\n",
    "    print('Handedness:', results.multi_handedness)\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    image_height, image_width, _ = image.shape\n",
    "    annotated_image = image.copy()\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "      print('hand_landmarks:', hand_landmarks)\n",
    "      print(\n",
    "          f'Index finger tip coordinates: (',\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "      )\n",
    "      mp_drawing.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks,\n",
    "          mp_hands.HAND_CONNECTIONS,\n",
    "          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "          mp_drawing_styles.get_default_hand_connections_style())\n",
    "    cv2.imwrite(\n",
    "        'annotated_image' + str(idx) + '.jpeg', cv2.flip(annotated_image, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4d4065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-33df21867f6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "# change to get xyz\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv2.flip(cv2.imread(file), 1)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print handedness and draw hand landmarks on the image.\n",
    "    print('Handedness:', results.multi_handedness)\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    image_height, image_width, _ = image.shape\n",
    "    annotated_image = image.copy()\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "      print('hand_landmarks:', hand_landmarks)\n",
    "      print(\n",
    "          f'Index finger tip coordinates: (',\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '\n",
    "          f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'\n",
    "      )\n",
    "      mp_drawing.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks,\n",
    "          mp_hands.HAND_CONNECTIONS,\n",
    "          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "          mp_drawing_styles.get_default_hand_connections_style())\n",
    "    cv2.imwrite(\n",
    "        '/tmp/annotated_image' + str(idx) + '.png', cv2.flip(annotated_image, 1))\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d6529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test holistic\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=2) as holistic:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "      print(\n",
    "          f'Nose coordinates: ('\n",
    "          f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, '\n",
    "          f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_height})'\n",
    "      )\n",
    "    # Draw pose, left and right hands, and face landmarks on the image.\n",
    "    annotated_image = image.copy()\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_tesselation_style())\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.\n",
    "        get_default_pose_landmarks_style())\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "    # Plot pose world landmarks.\n",
    "    mp_drawing.plot_landmarks(\n",
    "        results.pose_world_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as holistic:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = holistic.process(image)\n",
    "\n",
    "    # Draw landmark annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles\n",
    "        .get_default_pose_landmarks_style())\n",
    "    cv2.imshow('MediaPipe Holistic', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c61a73",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'SolutionOutputs' has no attribute 'multi_hand_landmarks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3c405ba7b2ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         .get_default_face_mesh_contours_style())\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mhand_landmarks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         mp_drawing.draw_landmarks(\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'SolutionOutputs' has no attribute 'multi_hand_landmarks'"
     ]
    }
   ],
   "source": [
    "# test holistic with hand\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=2) as holistic:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "      print(\n",
    "          f'Nose coordinates: ('\n",
    "          f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, '\n",
    "          f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_height})'\n",
    "      )\n",
    "    # Draw pose, left and right hands, and face landmarks on the image.\n",
    "    annotated_image = image.copy()\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_tesselation_style())\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.\n",
    "        get_default_pose_landmarks_style())\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "    # Plot pose world landmarks.\n",
    "    mp_drawing.plot_landmarks(\n",
    "        results.pose_world_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as holistic:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = holistic.process(image)\n",
    "\n",
    "    # Draw landmark annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "    \n",
    "#     if results.multi_hand_landmarks:\n",
    "#       for hand_landmarks in results.multi_hand_landmarks:\n",
    "#         mp_drawing.draw_landmarks(\n",
    "#             image,\n",
    "#             hand_landmarks,\n",
    "#             mp_holistic.HAND_CONNECTIONS,\n",
    "#             mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "#             mp_drawing_styles.get_default_hand_connections_style())\n",
    "        \n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles\n",
    "        .get_default_pose_landmarks_style())\n",
    "    cv2.imshow('MediaPipe Holistic', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2b2b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "count = 0\n",
    "alldata = []\n",
    "fps_time = 0\n",
    "\n",
    "pose_tubuh = ['NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "              'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT',\n",
    "              'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', 'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY',\n",
    "              'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX', 'LEFT_THUMB',\n",
    "              'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "              'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX']\n",
    "\n",
    "pose_tangan = ['WRIST', 'THUMB_CPC', 'THUMB_MCP', 'THUMB_IP', 'THUMB_TIP', 'INDEX_FINGER_MCP', 'INDEX_FINGER_PIP',\n",
    "               'INDEX_FINGER_DIP', 'INDEX_FINGER_TIP', 'MIDDLE_FINGER_MCP',\n",
    "               'MIDDLE_FINGER_PIP', 'MIDDLE_FINGER_DIP', 'MIDDLE_FINGER_TIP', 'RING_FINGER_PIP', 'RING_FINGER_DIP',\n",
    "               'RING_FINGER_TIP',\n",
    "               'RING_FINGER_MCP', 'PINKY_MCP', 'PINKY_PIP', 'PINKY_DIP', 'PINKY_TIP']\n",
    "\n",
    "pose_tangan_2 = ['WRIST2', 'THUMB_CPC2', 'THUMB_MCP2', 'THUMB_IP2', 'THUMB_TIP2', 'INDEX_FINGER_MCP2',\n",
    "                 'INDEX_FINGER_PIP2', 'INDEX_FINGER_DIP2', 'INDEX_FINGER_TIP2', 'MIDDLE_FINGER_MCP2',\n",
    "                 'MIDDLE_FINGER_PIP2', 'MIDDLE_FINGER_DIP2', 'MIDDLE_FINGER_TIP2', 'RING_FINGER_PIP2',\n",
    "                 'RING_FINGER_DIP2', 'RING_FINGER_TIP2',\n",
    "                 'RING_FINGER_MCP2', 'PINKY_MCP2', 'PINKY_PIP2', 'PINKY_DIP2', 'PINKY_TIP2']\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "# suc,frame_video = cap.read()\n",
    "# vid_writer = cv2.VideoWriter('pose.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_video.shape[1], frame_video.shape[0]))\n",
    "with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Draw landmark annotation on the image.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image_asli = np.copy(image)\n",
    "        image = np.zeros(image.shape)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "        #  if(results.pose_landmarks is not None and results.left_hand_landmarks is not None and results.right_hand_landmarks is not None):\n",
    "        if results.pose_landmarks:\n",
    "            data_tubuh = {}\n",
    "            for i in range(len(pose_tubuh)):\n",
    "                results.pose_landmarks.landmark[i].x = results.pose_landmarks.landmark[i].x * image.shape[0]\n",
    "                results.pose_landmarks.landmark[i].y = results.pose_landmarks.landmark[i].y * image.shape[1]\n",
    "                data_tubuh.update(\n",
    "                    {pose_tubuh[i]: results.pose_landmarks.landmark[i]}\n",
    "                )\n",
    "            alldata.append(data_tubuh)\n",
    "\n",
    "        if results.right_hand_landmarks:\n",
    "            data_tangan_kanan = {}\n",
    "            for i in range(len(pose_tangan)):\n",
    "                results.right_hand_landmarks.landmark[i].x = results.right_hand_landmarks.landmark[i].x * image.shape[0]\n",
    "                results.right_hand_landmarks.landmark[i].y = results.right_hand_landmarks.landmark[i].y * image.shape[1]\n",
    "                data_tubuh.update(\n",
    "                    {pose_tangan[i]: results.right_hand_landmarks.landmark[i]}\n",
    "                )\n",
    "            alldata.append(data_tubuh)\n",
    "\n",
    "        if results.left_hand_landmarks:\n",
    "            data_tangan_kiri = {}\n",
    "            for i in range(len(pose_tangan)):\n",
    "                results.left_hand_landmarks.landmark[i].x = results.left_hand_landmarks.landmark[i].x * image.shape[0]\n",
    "                results.left_hand_landmarks.landmark[i].y = results.left_hand_landmarks.landmark[i].y * image.shape[1]\n",
    "                data_tubuh.update(\n",
    "                    {pose_tangan_2[i]: results.left_hand_landmarks.landmark[i]}\n",
    "                )\n",
    "            alldata.append(data_tubuh)\n",
    "\n",
    "        # cv2.namedWindow('MediaPipe Holistic', cv2.WND_PROP_FULLSCREEN)\n",
    "        # cv2.setWindowProperty('MediaPipe Holistic', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "        cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2, )\n",
    "        cv2.imshow('MediaPipe Holistic', image)  # sudah menampilkan backgrounnd hitam dan skeleton\n",
    "        cv2.imshow('Gambar asli', image_asli)\n",
    "        count = count + 1\n",
    "        print(count)\n",
    "        fps_time = time.time()\n",
    "        # vid_writer.write(image)\n",
    "        # plt.imshow((image*255).astype(np.uint8))\n",
    "        # plt.savefig(\"image-frame/\" + str(count) + \".jpg\")\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            df = pd.DataFrame(alldata)\n",
    "            df.to_excel(\"koordinat.xlsx\")\n",
    "            break\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9c043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
